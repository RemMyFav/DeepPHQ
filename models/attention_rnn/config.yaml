# ===========================
#   DeepPHQ Transformer Config
# ===========================

data:
    level: "word" # options: "word", "sentence", "dialogue"
    data_root: "../../data/processed"
    word_csv: "word_level.csv"
    sentence_csv: "sentence_level.csv"
    dialogue_csv: "dialogue_level.csv"
    max_length: 512

vocab:
    min_freq: 1
    pad_token: "<PAD>"
    unk_token: "<UNK>"

dataloader:
    batch_size: 16
    num_workers: 2

model:
    model_type: "han"
    embed_dim: 100          
    hidden_dim: 64          
    dropout: 0.1
    max_words: 300         
    max_sentences: 40       
    output_size: 1


training:
    device: "cuda" # "cuda" or "cpu"
    num_epochs: 10
    learning_rate: 3e-4
    weight_decay: 1e-5
    gradient_clip: 1.0

checkpoint:
    save_dir: "../../models/checkpoints"
    filename: "han_network.pt"