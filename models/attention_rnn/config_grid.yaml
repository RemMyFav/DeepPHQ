# ===========================
#   DeepPHQ Transformer Config
# ===========================

data:
    level: "word" # options: "word", "sentence", "dialogue"
    data_root: "../../data/processed"
    word_csv: "word_level.csv"
    sentence_csv: "sentence_level.csv"
    dialogue_csv: "dialogue_level.csv"
    max_length: 512

vocab:
    min_freq: 1
    pad_token: "<PAD>"
    unk_token: "<UNK>"

dataloader:
    batch_size: 16
    num_workers: 2

model_grid:
  embed_dim: [64, 128, 256]
  hidden_dim: [32, 64, 128]
  dropout: [0.1, 0.5]
  max_words: [50, 100, 300]
  max_sentences: [10,20,30]

training_grid:
  learning_rate: [5e-5, 1e-5]
  weight_decay: [1e-5]
  gradient_clip: [1.0]
  num_epochs: [5]

checkpoint:
    save_dir: "../../models/checkpoints"
    filename: "han_network.pt"