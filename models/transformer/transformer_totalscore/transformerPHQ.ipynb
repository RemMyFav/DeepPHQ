{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 1. Load Paramter From Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "PROJECT_ROOT = Path.cwd().resolve().parents[1]\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "print(\"Loaded project root:\", PROJECT_ROOT)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from src.dataset import DeepPHQDataset, build_vocab, create_balanced_dataloader, split_by_pid, DeepPHQValDataset\n",
    "from models.transformer.transformer_model import DeepPHQTransformer\n",
    "import yaml\n",
    "\n",
    "# Load config\n",
    "CONFIG_PATH = Path(\"config.yaml\")\n",
    "\n",
    "with open(CONFIG_PATH, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# 2. Load processed CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cfg = config[\"data\"]\n",
    "root = Path(data_cfg[\"data_root\"])\n",
    "\n",
    "level = data_cfg[\"level\"]\n",
    "\n",
    "if level == \"word\":\n",
    "    csv_path = root / data_cfg[\"word_csv\"]\n",
    "elif level == \"sentence\":\n",
    "    csv_path = root / data_cfg[\"sentence_csv\"]\n",
    "elif level == \"dialogue\":\n",
    "    csv_path = root / data_cfg[\"dialogue_csv\"]\n",
    "else:\n",
    "    raise ValueError(\"Unknown level in config\")\n",
    "\n",
    "print(\"Loading:\", csv_path)\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# 3. Build Vocab and Balanced DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = df[\"Text\"].tolist()\n",
    "vocab = build_vocab(all_texts, min_freq=config[\"vocab\"][\"min_freq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. split\n",
    "train_df, val_df, test_df = split_by_pid(df)\n",
    "\n",
    "# 2. create datasets\n",
    "train_dataset = DeepPHQDataset(\n",
    "    data=list(zip(train_df[\"PID\"], train_df[\"Text\"], train_df[\"PHQ_Score\"])),\n",
    "    vocab=vocab,\n",
    "    max_length=config[\"data\"][\"max_length\"]\n",
    ")\n",
    "\n",
    "val_dataset = DeepPHQValDataset(\n",
    "    val_df,\n",
    "    vocab,\n",
    "    max_length=config[\"data\"][\"max_length\"],\n",
    "    stride=128\n",
    ")\n",
    "test_dataset = DeepPHQValDataset(\n",
    "    test_df,\n",
    "    vocab,\n",
    "    max_length=config[\"data\"][\"max_length\"],\n",
    "    stride=128\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "# 3. dataloaders\n",
    "train_loader = create_balanced_dataloader(\n",
    "    train_dataset,\n",
    "    batch_size=config[\"dataloader\"][\"batch_size\"]\n",
    ")\n",
    "\n",
    "# 4. verify shapes\n",
    "batch = next(iter(train_loader))\n",
    "print(batch[\"input_ids\"].shape)\n",
    "print(batch[\"label\"].shape)\n",
    "print(batch[\"pid\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# 4. Init Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Load model config ----\n",
    "model_cfg = config[\"model\"]\n",
    "\n",
    "# ---- Auto-select device ----\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ---- Init model ----\n",
    "model = DeepPHQTransformer(\n",
    "    input_size=len(vocab),\n",
    "    output_size=model_cfg[\"output_size\"],\n",
    "    hidden_dim=model_cfg[\"hidden_dim\"],\n",
    "    nhead=model_cfg[\"nhead\"],\n",
    "    num_layers=model_cfg[\"num_layers\"],\n",
    "    dropout=model_cfg[\"dropout\"]\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# 5. Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pid_level(model, val_loader, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    pid2preds = {}\n",
    "    pid2labels = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            labels = batch[\"label\"].cpu().numpy()\n",
    "            pids = batch[\"pid\"].cpu().numpy()\n",
    "\n",
    "            outputs = model(input_ids).squeeze().cpu().numpy()\n",
    "\n",
    "            for pid, lab, pred in zip(pids, labels, outputs):\n",
    "                pid2preds.setdefault(pid, []).append(pred)\n",
    "                pid2labels[pid] = lab  # same true PHQ for all windows\n",
    "\n",
    "    final_preds = []\n",
    "    final_labels = []\n",
    "\n",
    "    for pid in pid2preds:\n",
    "        final_preds.append(np.mean(pid2preds[pid]))\n",
    "        final_labels.append(pid2labels[pid])\n",
    "\n",
    "    final_preds = np.array(final_preds)\n",
    "    final_labels = np.array(final_labels)\n",
    "\n",
    "    mse = ((final_preds - final_labels) ** 2).mean()\n",
    "    mae = np.abs(final_preds - final_labels).mean()\n",
    "    rmse = mse ** 0.5\n",
    "\n",
    "    return mse, mae, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cfg = config[\"training\"]\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=float(train_cfg[\"learning_rate\"]),\n",
    "    weight_decay=float(train_cfg[\"weight_decay\"])\n",
    ")\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "train_losses = []\n",
    "val_mses = []\n",
    "val_maes = []\n",
    "val_rmses = []\n",
    "\n",
    "for epoch in range(train_cfg[\"num_epochs\"]):\n",
    "    # ==========================\n",
    "    #   1. TRAIN\n",
    "    # ==========================\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    progress = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "\n",
    "    for batch in progress:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids).squeeze()\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), train_cfg[\"gradient_clip\"])\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        progress.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # ==========================\n",
    "    #   2. PID-LEVEL VALIDATION\n",
    "    # ==========================\n",
    "    mse, mae, rmse = evaluate_pid_level(model, val_loader, device)\n",
    "\n",
    "    val_mses.append(mse)\n",
    "    val_maes.append(mae)\n",
    "    val_rmses.append(rmse)\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] \"\n",
    "          f\"Train Loss = {avg_train_loss:.4f} | \"\n",
    "          f\"Val MSE = {mse:.4f} | Val MAE = {mae:.4f} | Val RMSE = {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# 6. Save Result as pt Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path(config[\"checkpoint\"][\"save_dir\"])\n",
    "level = config[\"data\"][\"level\"]   # \"word\", \"sentence\", \"dialogue\"\n",
    " \n",
    "model_name = f\"{level}.pt\"\n",
    "save_path = save_dir / model_name\n",
    "\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "torch.save({\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"vocab\": vocab,\n",
    "    \"config\": config,\n",
    "}, save_path)\n",
    "\n",
    "print(f\"[âœ“] Saved model to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label=\"Train Loss (MSE)\")\n",
    "plt.plot(val_mses, label=\"Val MSE\")\n",
    "plt.plot(val_maes, label=\"Val MAE\")\n",
    "plt.plot(val_rmses, label=\"Val RMSE\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Validation Loss (PID-level)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
