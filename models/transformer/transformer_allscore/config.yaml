# ===========================
#   DeepPHQ Transformer Config
# ===========================

data:
    level: "dialogue" # options: "word", "sentence", "dialogue"
    data_root: "../../../data/processed/all_score/"
    word_csv: "word_level.csv"
    sentence_csv: "sentence_level.csv"
    dialogue_csv: "dialogue_level.csv"
    max_length: 512

vocab:
    min_freq: 1
    pad_token: "<PAD>"
    unk_token: "<UNK>"

dataloader:
    batch_size: 64
    num_workers: 0

model:
    hidden_dim: 96
    nhead: 3
    num_layers: 2
    dropout: 0.2
    output_size: 8

training:
    device: "cuda" # "cuda" or "cpu"
    num_epochs: 10
    learning_rate: 2e-5
    weight_decay: 1e-4
    gradient_clip: 1.0

checkpoint:
    save_dir: "../../../models/transformer/transformer_allscore/"
    filename: "deepphq_transformer.pt"
