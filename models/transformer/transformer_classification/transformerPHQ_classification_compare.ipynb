{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_model_classification import DeepPHQTransformer\n",
    "from dataset_classification import DeepPHQDataset, DeepPHQValDataset, build_vocab, create_balanced_dataloader, split_by_pid\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using device: MPS\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using device: CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(pt_path, device):\n",
    "    ckpt = torch.load(pt_path, map_location=device, weights_only=False)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 1. Read config + vocab\n",
    "    # -------------------------------\n",
    "    config = ckpt[\"config\"]\n",
    "    vocab = ckpt[\"vocab\"]\n",
    "\n",
    "    model_cfg = config[\"model\"]\n",
    "\n",
    "    # CORRECT reconstruction of CORAL model\n",
    "    model = DeepPHQTransformer(\n",
    "        input_size=len(vocab),\n",
    "        hidden_dim=model_cfg[\"hidden_dim\"],\n",
    "        nhead=model_cfg[\"nhead\"],\n",
    "        num_layers=model_cfg[\"num_layers\"],\n",
    "        dropout=model_cfg[\"dropout\"],\n",
    "        num_items=model_cfg.get(\"num_items\", 8),\n",
    "        num_levels=4,    # fixed for PHQ 0-3\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2. Load weights\n",
    "    # -------------------------------\n",
    "    model.load_state_dict(ckpt[\"model_state\"], strict=True)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3. MOVE everything to device\n",
    "    # -------------------------------\n",
    "    model.to(device)\n",
    "\n",
    "    # --- FIX #1: MPS cannot auto-move embedding ---\n",
    "    model.embedding.weight.data = model.embedding.weight.data.to(device)\n",
    "\n",
    "    # --- FIX #2: PositionalEncoding buffer must also move ---\n",
    "    model.pos_encoder.pe = model.pos_encoder.pe.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    return model, vocab, config\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "model_word, vocab_word, cfg_word = load_model(\"./checkpoints/deep_phq_word.pt\", device)\n",
    "model_sentence, vocab_sentence, cfg_sentence = load_model(\"./checkpoints/deep_phq_sentence.pt\", device)\n",
    "model_dialogue, vocab_dialogue, cfg_dialogue = load_model(\"./checkpoints/deep_phq_dialogue.pt\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_loader(csv_path, vocab, max_length, batch_size=32):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    dataset = DeepPHQValDataset(\n",
    "        df,\n",
    "        vocab=vocab,\n",
    "        max_length=max_length,\n",
    "        stride=128,\n",
    "    )\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    return loader\n",
    "\n",
    "loader_word     = build_loader(cfg_word[\"data\"][\"data_root\"] + cfg_word[\"data\"][\"word_csv\"],\n",
    "                               vocab_word, \n",
    "                               cfg_word[\"data\"][\"max_length\"])\n",
    "\n",
    "loader_sentence = build_loader(cfg_sentence[\"data\"][\"data_root\"] + cfg_sentence[\"data\"][\"sentence_csv\"],\n",
    "                               vocab_sentence, \n",
    "                               cfg_sentence[\"data\"][\"max_length\"])\n",
    "\n",
    "loader_dialogue = build_loader(cfg_dialogue[\"data\"][\"data_root\"] + cfg_dialogue[\"data\"][\"dialogue_csv\"],\n",
    "                               vocab_dialogue, \n",
    "                               cfg_dialogue[\"data\"][\"max_length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pid_level(model, val_loader, device=\"cpu\", return_preds=False):\n",
    "    model.eval()\n",
    "\n",
    "    pid2preds = {}      # pid → list of (8,) predicted ordinal scores\n",
    "    pid2labels = {}     # pid → vector (8,)\n",
    "    pid_order = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "\n",
    "            # always move inputs to device\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "\n",
    "            labels = batch[\"label\"].numpy()    # labels always CPU is ok\n",
    "            pids   = batch[\"pid\"].numpy()\n",
    "\n",
    "            logits = model(input_ids)          # (B, 8, 3)\n",
    "            probs = torch.sigmoid(logits)      # (B, 8, 3)\n",
    "\n",
    "            # Expected ordinal score = sum(P(score ≥ k))\n",
    "            expected_scores = probs.sum(dim=2).cpu().numpy()\n",
    "\n",
    "            for pid, lab_vec, pred_vec in zip(pids, labels, expected_scores):\n",
    "                pid2preds.setdefault(pid, []).append(pred_vec)\n",
    "                pid2labels[pid] = lab_vec\n",
    "\n",
    "    # ----------------------------\n",
    "    # Aggregate PID-level predictions\n",
    "    # ----------------------------\n",
    "    final_pred_totals = []\n",
    "    final_label_totals = []\n",
    "\n",
    "    for pid in pid2preds:\n",
    "        preds = np.stack(pid2preds[pid])      # (num_windows, 8)\n",
    "        pred_mean_items = preds.mean(axis=0)  # (8,)\n",
    "        pred_total = pred_mean_items.sum()\n",
    "\n",
    "        label_items = pid2labels[pid]\n",
    "        label_total = label_items.sum()\n",
    "\n",
    "        pid_order.append(pid)\n",
    "        final_pred_totals.append(pred_total)\n",
    "        final_label_totals.append(label_total)\n",
    "\n",
    "    # convert to numpy\n",
    "    final_pred_totals = np.array(final_pred_totals)\n",
    "    final_label_totals = np.array(final_label_totals)\n",
    "\n",
    "    # metrics\n",
    "    mse  = ((final_pred_totals - final_label_totals) ** 2).mean()\n",
    "    mae  = np.abs(final_pred_totals - final_label_totals).mean()\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    if return_preds:\n",
    "        return mse, mae, rmse, final_pred_totals, final_label_totals, pid_order\n",
    "\n",
    "    return mse, mae, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_word = evaluate_pid_level(model_word, loader_word, device=device, return_preds=True)\n",
    "eval_sentence = evaluate_pid_level(model_sentence, loader_sentence, device=device, return_preds=True)\n",
    "eval_dialogue = evaluate_pid_level(model_dialogue, loader_dialogue, device=device, return_preds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_curve(pt_path):\n",
    "    ckpt = torch.load(pt_path, map_location=\"cpu\", weights_only=False)\n",
    "    return ckpt[\"train_mse\"], ckpt[\"val_mse\"]\n",
    "    \n",
    "train_w, val_w = load_curve(\"./checkpoints/deep_phq_word.pt\")\n",
    "train_s, val_s = load_curve(\"./checkpoints/deep_phq_sentence.pt\")\n",
    "train_d, val_d = load_curve(\"./checkpoints/deep_phq_dialogue.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_values = [mse_w, mse_s, mse_d]\n",
    "labels = [\"word\", \"sentence\", \"dialogue\"]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(labels, mse_values, color=[\"#4c72b0\", \"#55a868\", \"#c44e52\"])\n",
    "\n",
    "plt.title(\"Test MSE Comparison\")\n",
    "plt.ylabel(\"PID-Level MSE\")\n",
    "plt.xlabel(\"Input-Level\")\n",
    "\n",
    "\n",
    "for i, v in enumerate(mse_values):\n",
    "    plt.text(i, v + 0.1, f\"{v:.2f}\", ha='center', fontsize=10)\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(train_w, label=\"word\")\n",
    "plt.plot(train_s, label=\"sentence\")\n",
    "plt.plot(train_d, label=\"dialogue\")\n",
    "\n",
    "plt.title(\"Training CORAL Loss Across Granularity\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"CORAL Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(val_w, label=\"word\")\n",
    "plt.plot(val_s, label=\"sentence\")\n",
    "plt.plot(val_d, label=\"dialogue\")\n",
    "\n",
    "plt.title(\"Validation CORAL Loss Across Granularity\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"CORAL Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(train_w, label=\"train word\")\n",
    "plt.plot(val_w, label=\"val word\")\n",
    "\n",
    "plt.plot(train_s, label=\"train sentence\")\n",
    "plt.plot(val_s, label=\"val sentence\")\n",
    "\n",
    "plt.plot(train_d, label=\"train dialogue\")\n",
    "plt.plot(val_d, label=\"val dialogue\")\n",
    "\n",
    "plt.title(\"Train/Val PID-Level MSE Across Granularity\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Train Loss:\")\n",
    "print(\"  word     =\", train_w[-1])\n",
    "print(\"  sentence =\", train_s[-1])\n",
    "print(\"  dialogue =\", train_d[-1])\n",
    "\n",
    "print(\"\\nFinal Val Loss:\")\n",
    "print(\"  word     =\", val_w[-1])\n",
    "print(\"  sentence =\", val_s[-1])\n",
    "print(\"  dialogue =\", val_d[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
