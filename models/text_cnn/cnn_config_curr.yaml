# ===========================
#   DeepPHQ LSTM Config
# ===========================

data:
    level: "word" # options: "word", "sentence", "dialogue"
    data_root: "../../data/processed"
    word_csv: "word_level.csv"
    sentence_csv: "sentence_level.csv"
    dialogue_csv: "dialogue_level.csv"
    max_length: 512

vocab:
    min_freq: 1
    pad_token: "<PAD>"
    unk_token: "<UNK>"

dataloader:
    batch_size: 32
    num_workers: 2

model:
    pretrained_embedding: true
    embeddings_file: "glove_wiki50/wiki_giga_2024_50_MFT20_vectors_seed_123_alpha_0.75_eta_0.075_combined.txt"
    embeddings_dim: 50
    num_filters: 8
    kernel_sizes: [3, 4, 5]
    dropout: 0.1

training:
    device: "cuda" # "cuda" or "cpu"
    num_epochs: 10
    learning_rate: 3e-4
    weight_decay: 1e-5
    gradient_clip: 1.0
    seed: 2025

checkpoint:
    save_dir: "../../models/checkpoints"
    filename: "deepphq_cnn.pt"
