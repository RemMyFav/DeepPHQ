{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "# Just run this block. Please do not modify the following code.\n",
    "import math\n",
    "import time\n",
    "import io\n",
    "import numpy as np\n",
    "import csv\n",
    "from IPython.display import Image\n",
    "\n",
    "# Pytorch package\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Tqdm progress bar\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "# Code provide to you for training and evaluation\n",
    "# Not sure why this import doesn't work\n",
    "from utils import train, evaluate, set_seed_nb, plot_curves\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check device availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"You are using device: %s\" % device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the transcripts and process them into their relevent chunks\n",
    "from src import context_chunker \n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# --- Paths ---\n",
    "path = \"data/raw/transcripts\"\n",
    "meta_path = \"data/raw/full_test_split.csv\"\n",
    "\n",
    "# --- Load Data ---\n",
    "phq_transcript_alignment = context_chunker.match_phq_transcripts(path, meta_path)\n",
    "\n",
    "\n",
    "transcripts = context_chunker.generate_dataset(path, phq_transcript_alignment)\n",
    "\n",
    "\n",
    "# --- Build Representations \n",
    "sequence_len = 512\n",
    "num_samples_per_pid = 20\n",
    "output_dir = \"data/processed\"\n",
    "dataset_word, dataset_sentence, dataset_dialogue = context_chunker.build_text_representations(transcripts, sequence_len, num_samples_per_pid)\n",
    "\n",
    "context_chunker.save_text_representations(\n",
    "    dataset_word,\n",
    "    dataset_sentence,\n",
    "    dataset_dialogue,\n",
    "    output_dir\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the chunks generated above into train split datasets\n",
    "from src import dataset_builder\n",
    "\n",
    "# if datasets were not loaded previously, load from csv\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "\n",
    "df = pd.DataFrame(dataset_word, columns=[\"PID\",'Text', 'PHQ_Score'])\n",
    "normed_scores, score_mean, score_std = dataset_builder.normalize_scores(df[\"PHQ_Score\"])\n",
    "word_train, word_test, vocab = dataset_builder.preprocess_data(df[\"Text\"], normed_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import TextCNN\n",
    "from models import embeddings\n",
    "\n",
    "embeddings_file = \"models/glove_wiki50/wiki_giga_2024_50_MFT20_vectors_seed_123_alpha_0.75_eta_0.075_combined.txt\"\n",
    "\n",
    "#embedding_matrix = embeddings.load_embedding_file(embeddings_file)\n",
    "\n",
    "embedding_matrix = embeddings.create_embedding_matrix(vocab, embeddings_file, embedding_dim=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = TextCNN.CNNTextRegressor(len(vocab), embedding_dim = 50, kernel_size = 4, pretrained_embedding = True, embedding_matrix = embedding_matrix, freeze_embeddings = False)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "optimizer = torch.optim.Adam(cnn_model.parameters(),lr=0.001)\n",
    "\n",
    "history = train(cnn_model, criterion, optimizer, word_train, word_test, lr=0.001)\n",
    "results = evaluate(cnn_model, word_test)\n",
    "\n",
    "denormalized_predictions = dataset_builder.denormalize_predictions(results['predictions'], score_mean, score_std)\n",
    "denormalized_actual = dataset_builder.denormalize_predictions(results['actual'], score_mean, score_std)\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
